{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KUB5gpswan4"
      },
      "source": [
        "# Spiking Convolutional Neural Network in Speck\n",
        "\n",
        "In this section you will learn about Speck, a neuromorphic system that integrates a Dynamic Vision Sensor and a Spiking Convolutional Neural Network on device. In the following sections, you will learn how to interact with the Speck data, visualize them and how to train a network that can be loaded to Speck.\n",
        "\n",
        "You will train an SNN to solve a simple task and load it in Speck. You will then be able to run the network on inference and visualize its response in real time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjxpjy1syIwJ"
      },
      "source": [
        "## Speck device\n",
        "\n",
        "Speck is a neuromorphic device with characteristics in hardware and Samna has developed the software that we'll see"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwlFckrXyXLh"
      },
      "source": [
        "### Hardware\n",
        "\n",
        "Speck's [architecture](https://synsense-sys-int.gitlab.io/samna/models/speckSeries/summary.html) consist of a Dynamic Vision Sensor and a Spiking Convolutional Neural Network with the following characteristics\n",
        "\n",
        "- DVS input of 128x128 resolution\n",
        "- 9 convolutional layers\n",
        "- Implementation of Integrate and Fire neurons\n",
        "- Leak through bias and external clock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBNEH4WdysTS"
      },
      "source": [
        "### Software\n",
        "\n",
        "Synsense provides software libraries to develop neural networks and interact with Speck.\n",
        "\n",
        "- Communication with Speck relies on the [Samna](https://synsense-sys-int.gitlab.io/samna/index.html) library.\n",
        "- Simulator [sinabs-dynapcnn](https://synsense.gitlab.io/sinabs-dynapcnn/) used to train models offline and load them to Speck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm_LEMavzKxv"
      },
      "source": [
        "## Interaction with Speck\n",
        "\n",
        "In this section, we will see how to compute using speck input data, we will visualize events and develop a network for edge detection that we'll load to speck.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 0: Import libraries and data \n",
        "\n",
        "We will start our preparation by importing the libraries necessary and the data for our tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JBvVGv3cSPM"
      },
      "source": [
        "#### Task 0.1: Import libraries\n",
        "\n",
        "We begin by importing the necessary libraries for our implementation, such as samna, sinabs, torch and libraries to help us fetch and vsualize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbtvaX1fcMTE"
      },
      "outputs": [],
      "source": [
        "!pip install -q samna\n",
        "!pip install -q sinabs\n",
        "\n",
        "import samna\n",
        "import torch\n",
        "import pickle\n",
        "import tqdm\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from urllib.request import urlretrieve\n",
        "import sinabs.layers as sl\n",
        "from torch import nn\n",
        "from sinabs.activation.surrogate_gradient_fn import PeriodicExponential\n",
        "from operator import iconcat\n",
        "from functools import reduce\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--ZjjfmZVUD_"
      },
      "source": [
        "#### Task 0.2: Fetch data\n",
        "\n",
        "Now we will fetch the data files that we will use for our next experiment.\n",
        "\n",
        "You will notice that the format of the spikes is not the tensor format that has been previously discussed. What is this new format?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX-LEAPMVgwd",
        "outputId": "5894f1df-3e15-4c82-9e47-e170a662900a"
      },
      "outputs": [],
      "source": [
        "data_file, _ = urlretrieve(\"https://github.com/ncskth/phd-course/raw/main/book/module4/edge_detect\")\n",
        "with open(data_file, 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYCBwsHqzsPv"
      },
      "source": [
        "### Task 1: Visualize DVS output\n",
        "\n",
        "In this task you are asked to visualize your input data. Before working with the data, we should convert them in a friendly format (a tensor).\n",
        "\n",
        "Note that we bin events every 10000Î¼s (10ms). You will need this information when constructing the video from events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scH5ZaL4cMhq"
      },
      "outputs": [],
      "source": [
        "def events_to_channels(events, time_interval = 1000):\n",
        "    frames = []\n",
        "    index = 0\n",
        "    current_frame = torch.zeros(2, 128, 128)\n",
        "    for (t, y, x, p) in tqdm.tqdm(events.int()):\n",
        "        if t // time_interval > index:\n",
        "            frames.append(current_frame.clone())\n",
        "            current_frame.fill_(0)\n",
        "            index += 1\n",
        "        current_frame[p, x, y] = +1\n",
        "    return torch.stack(frames)\n",
        "\n",
        "\n",
        "def Speck_spikes_to_events(sp_events):\n",
        "\n",
        "  sp_events = reduce(iconcat, sp_events, [])\n",
        "  events = torch.zeros((len(sp_events), 4))\n",
        "  start = sp_events[0].timestamp\n",
        "\n",
        "  for i, e in tqdm.tqdm(enumerate(sp_events), total=len(sp_events)):\n",
        "    events[i][0] = e.timestamp - start\n",
        "    events[i][1] = e.x\n",
        "    events[i][2] = e.y\n",
        "    events[i][3] = e.feature\n",
        "  return events\n",
        "\n",
        "\n",
        "\n",
        "# Convert Speck spikes to tensor\n",
        "\n",
        "events = Speck_spikes_to_events(data)\n",
        "events = events_to_channels(events, 10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7REbex-zccsc"
      },
      "source": [
        "Use the functions that are provided in the cell bellow to create a video of your input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "t23uqv7u0Mg9",
        "outputId": "419777c6-e880-48d6-a78c-34e62e841944"
      },
      "outputs": [],
      "source": [
        "def animate_frames(frames, figure=None, interval: int = 20, **kwargs):\n",
        "    if figure is None:\n",
        "        figure, _ = plt.subplots(**kwargs)\n",
        "    ax = figure.gca()\n",
        "\n",
        "    image = ax.imshow(frames[0])  # .T)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    def animate(index):\n",
        "        image.set_data(frames[index])  # .T)\n",
        "        return image\n",
        "\n",
        "    anim = FuncAnimation(figure, animate, frames=len(frames), interval=interval)\n",
        "    video = anim.to_html5_video()\n",
        "    html = HTML(video)\n",
        "    display(html)\n",
        "    plt.tight_layout()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def events_to_frames(frames, polarity: bool = True):\n",
        "    if len(frames.shape) == 3:\n",
        "        frames = frames.unsqueeze(-1).repeat(1, 1, 1, 3)\n",
        "    else:\n",
        "        if not polarity:\n",
        "            frames = frames.abs().sum(-1)\n",
        "        elif polarity:\n",
        "            frames = torch.concat([frames, torch.zeros(frames.shape[0], 1, *frames.shape[2:], device=frames.device)], dim=1).movedim(1, -1)\n",
        "    frames = ((frames / frames.max()) * 255).int().clip(0, 255)\n",
        "    return frames\n",
        "\n",
        "# Visualize your input data\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71U9WNB9z9Bv"
      },
      "source": [
        "### Task 2: Create edge detector in sinabs\n",
        "\n",
        "For this task you will have to create an edge detector. You will need to create a Spiking Convolutional Neural Network that detects vertical and horizontal edges.\n",
        "\n",
        "Note that your neuros should be Integrate and Fire as Speck does not implement leak directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo5Sz7V_iymZ"
      },
      "source": [
        "#### Task 2.1: Convolutional layer\n",
        "\n",
        "In the following cell, you have an example of an edge detector. Use this as your kernel to develop your network. What should the shape of the convolutional layer's weights be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "m9Pkm3HP0NMN",
        "outputId": "31c02e92-84bf-4fae-c09d-eaf6cda67f99"
      },
      "outputs": [],
      "source": [
        "kernel_size = 9\n",
        "gaussian = torch.sigmoid(torch.linspace(-10, 10, kernel_size + 1))\n",
        "kernel = (gaussian.diff()-0.14).repeat(kernel_size, 1)\n",
        "plt.imshow(kernel)\n",
        "plt.colorbar()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjFUTt45jUtZ"
      },
      "source": [
        "#### Task 2.2: Network implementation\n",
        "\n",
        "For this task, you will have to implement and run your network using the sinabs library. This library will allow you to transfer your network to the Speck chip. You can use `sl.IAFSqueeze()` to implement the integration of spikes.\n",
        "\n",
        "Note: The biases should be set to None!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsp-onVUkRrB",
        "outputId": "c6d921ba-9529-4178-e7e3-490fe22e8cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "snn_bptt = nn.Sequential(\n",
        "    # [2, 128, 128] -> [2, 64, 64]\n",
        "    # Fill in your convolutional layer here. Note: Bias should be None!\n",
        "    sl.IAFSqueeze(batch_size=1, min_v_mem=-1.0),\n",
        "    )\n",
        "\n",
        "out = snn_bptt(events)\n",
        "\n",
        "# Every positive output of the network is a spike produced by the network. We threshold with out > 0 to normalize the output to 0 or 1 (spike or no spike) at each frame\n",
        "print(torch.sum(out - out.int()))\n",
        "out = (out > 0).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RSICMoltv2"
      },
      "outputs": [],
      "source": [
        "animate_frames(events_to_frames(out[:400], polarity=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptouyIrA0KUN"
      },
      "source": [
        "#### Task 2.3: Visualize the output\n",
        "\n",
        "Using the provided function above, visualize the output. What do you observe? How can you suppress the noise?\n",
        "\n",
        "Speck neurons can implement [leak](https://synsense.gitlab.io/sinabs-dynapcnn/getting_started/notebooks/leak_neuron.html) through their bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "934HX-fJtxw_"
      },
      "outputs": [],
      "source": [
        "# Visualize the output\n",
        "\n",
        "# ..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
