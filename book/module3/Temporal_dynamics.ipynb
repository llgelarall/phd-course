{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Time surfaces\n",
        "\n",
        "We will now explore the use of temporal dynamics of Leaky Integrators to address time domain problems.\n",
        "\n",
        "In the spatial domain, one can use the convolution operation to create neurons that respond to the activity of a specific region of the input signal, called receptive field. The neurons will be higly active if the input pattern within the receptive field matches the kernel of the convolution. In the temporal domain, these neurons can respond to temporal characteristics as well, such as the velocity of the moving pattern.\n",
        "\n",
        "To see how we can exploit such dynamics, we will implement a  model that can detect disks that move with different velocities."
      ],
      "metadata": {
        "id": "AwzLnVjIs6tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 0: Importing the libraries\n",
        "\n",
        "We begin by importing the necessary libraries for our implementation, such as norse, torch and libraries to help us fetch and vsualize our data."
      ],
      "metadata": {
        "id": "ocIkztnQINtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install norse\n",
        "\n",
        "import norse\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from urllib.request import urlretrieve"
      ],
      "metadata": {
        "id": "OO7Uc7OIIDCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Preprocessing the dataset\n",
        "\n",
        "Let's begin by obtaining and understanding the data. The data cosnist of events genetared from the motion of three disks in parallel in three different velocities. For this task, the polarity of the data has been ignored. Both the positive and negative polarity are considered the same and the data have the format (time, x, y).\n"
      ],
      "metadata": {
        "id": "mCBw-V7hv8DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 1.1: Loading the dataset\n",
        "\n",
        "The data are saved as a [sparse tensor](https://pytorch.org/docs/stable/sparse.html). This representation allows for memory efficient storage of the data but it is not so friendly to work with. You can convert it back to a dense tensor using `.to_dense()`."
      ],
      "metadata": {
        "id": "UbEYJISfJNCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file, _ = urlretrieve(\"https://github.com/ncskth/phd-course/raw/main/book/module3/2404_circle.dat\")\n",
        "data = torch.load(data_file)\n",
        "print(data.shape)\n",
        "print(data)\n",
        "\n",
        "# convert data to dense tensor\n",
        "# data = ...\n",
        "\n",
        "# print(data.shape)\n",
        "# print(data)"
      ],
      "metadata": {
        "id": "RzhDnCm3KSsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference in the shape and representation of the sparse and the dense tensor?"
      ],
      "metadata": {
        "id": "HUw8e86-LBFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 1.2: Visualization\n",
        "\n",
        "In order to understand the data that we are working with, it is ofter very useful to visualize it. Use the `animate_frames` function provided below to animate the input data."
      ],
      "metadata": {
        "id": "p2a1sDn6KTC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def animate_frames(frames, figure=None, interval: int = 20, **kwargs):\n",
        "    if figure is None:\n",
        "        figure, _ = plt.subplots(**kwargs)\n",
        "    ax = figure.gca()\n",
        "\n",
        "    image = ax.imshow(frames[0])  # .T)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    def animate(index):\n",
        "        image.set_data(frames[index])  # .T)\n",
        "        return image\n",
        "\n",
        "    anim = FuncAnimation(figure, animate, frames=len(frames), interval=interval)\n",
        "    video = anim.to_html5_video()\n",
        "    html = HTML(video)\n",
        "    display(html)\n",
        "    plt.tight_layout()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def events_to_frames(frames, polarity: bool = False):\n",
        "    if len(frames.shape) == 3:\n",
        "        frames = frames.unsqueeze(-1).repeat(1, 1, 1, 3)\n",
        "    else:\n",
        "        if not polarity:\n",
        "            frames = frames.abs().sum(-1)\n",
        "        elif polarity:\n",
        "            frames = torch.concat([frames, torch.zeros(frames.shape[0], 1, *frames.shape[2:], device=frames.device)], dim=1).movedim(1, -1)\n",
        "    frames = ((frames / frames.max()) * 255).int().clip(0, 255)\n",
        "    return frames"
      ],
      "metadata": {
        "id": "Rnjw8KFd5kdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize your data\n",
        "# ..."
      ],
      "metadata": {
        "id": "rXhyTblEyZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Model Implementation\n",
        "\n",
        "To solve this task, you will need to create a simple network to extract the position of the three disks that differ in velocity. The model should identify the position of the disks and the speed regime (slow, medium, fast) of their motion.\n"
      ],
      "metadata": {
        "id": "Z1ukTpv62GS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2.1: 2d convolutional kernel\n",
        "\n",
        "As a first step, you can perform a [2-dimenstional convolution](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "The convolution operation can be thought as pettern matching of the input with the kernel. The kernel is applied at every pixel of the input and the resulting value indicates how much the kernel matches the input at that position.\n",
        "\n",
        "To locate the position of the disks in space, you need to implement a kernel the shape of the disk (the ratio of the disk is 5 pixels.)\n",
        "It might be of help to fill the inner circle with zeros or negative values to avoid spurious activity.\n",
        "\n",
        "You can always come back and tune your kernel!\n",
        "\n",
        "Note that the weight matrix for the `Conv2d` layer should be 4-dimensional. (Why?)\n",
        "\n",
        "[torch.Tensor.unsqueeze_](https://pytorch.org/docs/stable/generated/torch.Tensor.unsqueeze_.html) and [torch.meshgrid](https://pytorch.org/docs/stable/generated/torch.meshgrid.html) could be useful for this task."
      ],
      "metadata": {
        "id": "EGOWEwxK7eJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def circular_kernel(radius):\n",
        "  # Implementation of a circular kernel to detect the moving disk\n",
        "  pass\n",
        "\n",
        "radius = 5\n",
        "circular_kernel_tensor = circular_kernel(radius)\n",
        "#plt.imshow(circular_kernel_tensor[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "d_2GPDnQqUBE",
        "outputId": "5eb8cbb8-306d-4ee3-8430-9aefa21def14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e253084b730>"
            ]
          },
          "metadata": {},
          "execution_count": 354
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Task 2.2: Temporal channels\n",
        "\n",
        "Now that you have your spatial computing layer, you can work on the temporal units. You  should use  LIFBoxCell neurons for your network. The output of the convolution can then be fed into three neuron layers (channels), operating in parallel, with different temporal dynamics.\n",
        "\n",
        "To implement your network, you can create a module that inherits from [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). You can define the `forward` function to perform the convolution and feed its output to the three LIFBoxCell neuron layers.\n",
        "The model should output the response of these temporal layers. Each layer should be tuned to respond to different regimes of speed.\n",
        "You are advised to tune both the `tau_mem_inv` and `v_th` values of your parameters."
      ],
      "metadata": {
        "id": "hMA4n4FW3HwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # correct the Conv2d() layer to have the correct number of input/output channels, kernel size, padding and bias settings\n",
        "    self.conv = torch.nn.Conv2d()\n",
        "    self.conv.weight.data = circular_kernel_tensor\n",
        "\n",
        "    # create the 3 different neuron layers to capture the disks\n",
        "    # self.parameters_1 = ...\n",
        "    # self.temporal_layer_1 = ...\n",
        "\n",
        "    # self.parameters_2 = ...\n",
        "    # ...\n",
        "\n",
        "  def forward(self, input):\n",
        "    state_1, state_2, state_3 = None, None, None\n",
        "    response_1, response_2, response_3 = [], [], []\n",
        "    for x in range(input.shape[0]):\n",
        "      # fill in the forward pass of each time step\n",
        "\n",
        "      # x = ...\n",
        "\n",
        "      pass\n",
        "\n",
        "    return response_1, response_2, response_3\n",
        "\n",
        "\n",
        "net = Network()\n",
        "response_1, response_2, response_3 = net(data.float())\n"
      ],
      "metadata": {
        "id": "N2MRmK-PvLPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2.3: Visualize your results\n",
        "\n",
        "To understand how the network behaves, it would be wise to visualize its output as a video. Using the `animate_frames` function provided in Task 1.2, visualize your results.\n",
        "\n",
        "To better visualize your results you could create a single animation and superimpose the activations of your model.\n",
        "\n",
        "<br>\n",
        "\n",
        "What do you observe? Is it possible to create selective neuron layers for all three different velocities?"
      ],
      "metadata": {
        "id": "xaZf-4XZNrKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize your results\n",
        "\n",
        "# animate input data\n",
        "# animate response 1\n",
        "# animate response 2\n",
        "# animate response 3\n",
        "\n",
        "# OR\n",
        "\n",
        "# animate input data superimposing the model's response"
      ],
      "metadata": {
        "id": "UUQkpklxOQgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 (Optional): Velocity selectivity\n",
        "\n",
        "In the previous implementation, the neurons are selective to velocities above certain thresholds. However, we might want the neurons to be responsive to a bounded range of velocities, while staying silent on higher or lower speeds. To work around this issue, we will try to modify the initial network to suppress undesired activity."
      ],
      "metadata": {
        "id": "BuskZbTOw8LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3.1: Inhibition\n",
        "\n",
        "In your model, there might have been unwanted activation in the 3 `LIFBoxCell` channels. Try to modify the forward pass of your model to inhibit such undesired activations. You can use the information of the other neurons' activity to inhibit certain channels of neurons."
      ],
      "metadata": {
        "id": "N4DIARfRPDIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network2(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # use the same network architecture as in Task 2.2\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    # perform the inhibition process\n",
        "    pass"
      ],
      "metadata": {
        "id": "LzekZL0USFt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize your results. How does the inhibition process affect the model's performance?"
      ],
      "metadata": {
        "id": "KA-l5kUvSqtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize your results\n",
        "# ..."
      ],
      "metadata": {
        "id": "PZph7-nHom0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3.2: Finetune model architecture\n",
        "\n",
        "No model is perfect! In your implementation, you might observe spurious activity away from the center of the disks as a result of the convolution operation. To suppress such activity, you can add a second layer that performs a smoothing operation. In this layer, you can use a convolution, such as a smoothing kernel, that is selective for activations in the center of the kernel with negative values in the surroundings. This will allow only for the most active regions, i.e. the center of the disks, to propagate events.\n",
        "\n",
        "You are encouraged to test different architectures and connectivities."
      ],
      "metadata": {
        "id": "dnmWp9lmS2qj"
      }
    }
  ]
}